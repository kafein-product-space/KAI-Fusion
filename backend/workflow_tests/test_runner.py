#!/usr/bin/env python3
"""
KAI-Fusion Workflow Test Runner - Terminal-based Workflow Testing
===============================================================

Bu araÃ§ terminal'den JSON ile workflow'larÄ± oluÅŸturup test etmemizi saÄŸlar.
Canvas UI'ya gerek kalmadan direkt workflow'larÄ± Ã§alÄ±ÅŸtÄ±rabilir, debug edebiliriz.

KullanÄ±m:
    python test_runner.py --workflow simple_openai.json
    python test_runner.py --create --template openai_chat
    python test_runner.py --list-nodes
    python test_runner.py --interactive

Ã–zellikler:
- JSON workflow dosyalarÄ±nÄ± yÃ¼kle ve Ã§alÄ±ÅŸtÄ±r
- Node template'leri ile hÄ±zlÄ± workflow oluÅŸtur
- Interactive mode ile adÄ±m adÄ±m workflow build et
- Test sonuÃ§larÄ±nÄ± analiz et ve kaydet
- Her node tÃ¼rÃ¼ iÃ§in hazÄ±r template'ler
"""

import argparse
import json
import os
import sys
import time
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional

# Backend import iÃ§in path ekle
sys.path.append(str(Path(__file__).parent.parent))

from app.core.engine_v2 import LangGraphWorkflowEngine
from app.core.state import FlowState
from app.nodes import *  # Import all nodes


class WorkflowTestRunner:
    """Workflow test runner sÄ±nÄ±fÄ±."""
    
    def __init__(self):
        self.engine = LangGraphWorkflowEngine()
        self.test_results_dir = Path(__file__).parent / "test_results"
        self.templates_dir = Path(__file__).parent / "templates"
        
        # Dizinleri oluÅŸtur
        self.test_results_dir.mkdir(exist_ok=True)
        self.templates_dir.mkdir(exist_ok=True)
        
        # Available nodes'larÄ± manuel olarak tanÄ±mla
        self.available_nodes = {
            "Start": StartNode,
            "End": EndNode,
            "WebhookStart": WebhookStartNode,
            "TimerStart": TimerStartNode,
            "OpenAIGPT": OpenAINode,
            "OpenAIChat": OpenAIChatNode,
            "Agent": ReactAgentNode,
            "ToolAgent": ToolAgentNode,
            "OpenAIDocumentEmbedder": OpenAIEmbedderNode,
            "ConversationMemory": ConversationMemoryNode,
            "BufferMemory": BufferMemoryNode,
            "TavilyWebSearch": TavilySearchNode,
            "DocumentReranker": RerankerNode,
            "HTTPClient": HttpClientNode,
            "WebScraper": WebScraperNode,
            "DocumentChunkSplitter": ChunkSplitterNode,
            "PostgreSQLVectorStore": PGVectorStoreNode,
            "RAGQuestionAnswering": RetrievalQANode,
        }
        
        print(f"ğŸš€ KAI-Fusion Workflow Test Runner initialized")
        print(f"ğŸ“ Test results: {self.test_results_dir}")
        print(f"ğŸ“„ Templates: {self.templates_dir}")
        print(f"ğŸ§© Available nodes: {len(self.available_nodes)}")

    def list_available_nodes(self):
        """Mevcut node'larÄ± listele."""
        print("\nğŸ§© Available Nodes:")
        print("=" * 50)
        
        # Kategorilere gÃ¶re grupla
        categories = {}
        for node_type, node_class in self.available_nodes.items():
            try:
                instance = node_class()
                category = instance._metadata.get("category", "Unknown")
                
                if category not in categories:
                    categories[category] = []
                
                categories[category].append({
                    "type": node_type,
                    "name": instance._metadata.get("display_name", node_type),
                    "description": instance._metadata.get("description", "No description")[:80] + "..."
                })
            except Exception as e:
                print(f"âš ï¸  Error loading {node_type}: {e}")
        
        # Kategorileri yazdÄ±r
        for category, nodes in sorted(categories.items()):
            print(f"\nğŸ“‚ {category}:")
            for node in nodes:
                print(f"  â€¢ {node['name']} ({node['type']})")
                print(f"    {node['description']}")

    def create_workflow_template(self, template_name: str) -> Dict[str, Any]:
        """HazÄ±r workflow template'i oluÅŸtur."""
        templates = {
            "simple_openai": {
                "name": "Simple OpenAI Chat",
                "description": "Basic OpenAI chat workflow",
                "nodes": [
                    {
                        "id": "start_1",
                        "type": "StartNode",
                        "position": {"x": 100, "y": 100},
                        "data": {
                            "initial_input": "Hello, how are you?"
                        }
                    },
                    {
                        "id": "openai_1",
                        "type": "OpenAINode",
                        "position": {"x": 400, "y": 100},
                        "data": {
                            "model_name": "gpt-4o",
                            "temperature": 0.7,
                            "max_tokens": 500,
                            "api_key": "your-openai-api-key-here"
                        }
                    },
                    {
                        "id": "end_1",
                        "type": "EndNode", 
                        "position": {"x": 700, "y": 100},
                        "data": {}
                    }
                ],
                "edges": [
                    {"id": "e1", "source": "start_1", "target": "openai_1"},
                    {"id": "e2", "source": "openai_1", "target": "end_1"}
                ]
            },
            
            "rag_pipeline": {
                "name": "RAG Pipeline",
                "description": "Complete RAG workflow with embeddings",
                "nodes": [
                    {
                        "id": "start_1",
                        "type": "StartNode",
                        "position": {"x": 50, "y": 100},
                        "data": {
                            "initial_input": "What is artificial intelligence?"
                        }
                    },
                    {
                        "id": "webscraper_1",
                        "type": "WebScraperNode",
                        "position": {"x": 200, "y": 100},
                        "data": {
                            "url": "https://en.wikipedia.org/wiki/Artificial_intelligence",
                            "max_chars": 5000
                        }
                    },
                    {
                        "id": "splitter_1",
                        "type": "ChunkSplitterNode",
                        "position": {"x": 350, "y": 100},
                        "data": {
                            "chunk_size": 1000,
                            "chunk_overlap": 200
                        }
                    },
                    {
                        "id": "embedder_1",
                        "type": "OpenAIEmbedderNode",
                        "position": {"x": 500, "y": 100},
                        "data": {
                            "model_name": "text-embedding-3-small",
                            "api_key": "your-openai-api-key-here"
                        }
                    },
                    {
                        "id": "vectorstore_1",
                        "type": "PGVectorStoreNode",
                        "position": {"x": 650, "y": 100},
                        "data": {
                            "connection_string": "postgresql://user:pass@localhost/vectordb",
                            "collection_name": "test_docs"
                        }
                    },
                    {
                        "id": "retrieval_1",
                        "type": "RetrievalQANode",
                        "position": {"x": 800, "y": 100},
                        "data": {
                            "k": 3
                        }
                    },
                    {
                        "id": "openai_1",
                        "type": "OpenAINode",
                        "position": {"x": 950, "y": 100},
                        "data": {
                            "model_name": "gpt-4o",
                            "temperature": 0.1,
                            "max_tokens": 1000,
                            "api_key": "your-openai-api-key-here"
                        }
                    },
                    {
                        "id": "end_1",
                        "type": "EndNode",
                        "position": {"x": 1100, "y": 100},
                        "data": {}
                    }
                ],
                "edges": [
                    {"id": "e1", "source": "start_1", "target": "webscraper_1"},
                    {"id": "e2", "source": "webscraper_1", "target": "splitter_1"},
                    {"id": "e3", "source": "splitter_1", "target": "embedder_1"},
                    {"id": "e4", "source": "embedder_1", "target": "vectorstore_1"},
                    {"id": "e5", "source": "vectorstore_1", "target": "retrieval_1"},
                    {"id": "e6", "source": "retrieval_1", "target": "openai_1"},
                    {"id": "e7", "source": "openai_1", "target": "end_1"}
                ]
            },
            
            "webhook_trigger": {
                "name": "Webhook Triggered Workflow",
                "description": "Workflow triggered by webhook",
                "nodes": [
                    {
                        "id": "webhook_start_1",
                        "type": "WebhookStartNode",
                        "position": {"x": 100, "y": 100},
                        "data": {
                            "require_auth": True,
                            "allowed_origins": "*"
                        }
                    },
                    {
                        "id": "openai_1",
                        "type": "OpenAINode",
                        "position": {"x": 400, "y": 100},
                        "data": {
                            "model_name": "gpt-4o",
                            "temperature": 0.7,
                            "max_tokens": 500,
                            "api_key": "your-openai-api-key-here"
                        }
                    },
                    {
                        "id": "http_client_1",
                        "type": "HttpClientNode",
                        "position": {"x": 700, "y": 100},
                        "data": {
                            "method": "POST",
                            "url": "https://webhook.site/your-endpoint",
                            "content_type": "json",
                            "body": '{"result": "{{ result }}", "status": "completed"}'
                        }
                    }
                ],
                "edges": [
                    {"id": "e1", "source": "webhook_start_1", "target": "openai_1"},
                    {"id": "e2", "source": "openai_1", "target": "http_client_1"}
                ]
            }
        }
        
        if template_name not in templates:
            available = ", ".join(templates.keys())
            raise ValueError(f"Template '{template_name}' not found. Available: {available}")
        
        return templates[template_name]

    def save_template(self, template_name: str, workflow: Dict[str, Any]):
        """Template'i dosyaya kaydet."""
        template_file = self.templates_dir / f"{template_name}.json"
        with open(template_file, 'w', encoding='utf-8') as f:
            json.dump(workflow, f, indent=2, ensure_ascii=False)
        print(f"âœ… Template saved: {template_file}")

    def load_workflow(self, workflow_file: str) -> Dict[str, Any]:
        """JSON workflow dosyasÄ±nÄ± yÃ¼kle."""
        if not os.path.exists(workflow_file):
            raise FileNotFoundError(f"Workflow file not found: {workflow_file}")
        
        with open(workflow_file, 'r', encoding='utf-8') as f:
            workflow = json.load(f)
        
        print(f"ğŸ“„ Loaded workflow: {workflow.get('name', 'Unnamed')}")
        print(f"ğŸ§© Nodes: {len(workflow.get('nodes', []))}")
        print(f"ğŸ”— Edges: {len(workflow.get('edges', []))}")
        
        return workflow

    async def execute_workflow(self, workflow: Dict[str, Any], input_text: str = None) -> Dict[str, Any]:
        """Workflow'Ä± Ã§alÄ±ÅŸtÄ±r."""
        print(f"\nğŸš€ Executing workflow: {workflow.get('name', 'Unnamed')}")
        print("=" * 50)
        
        start_time = time.time()
        
        try:
            # Input'u belirle
            if input_text is None:
                # Ä°lk node'dan initial input'u al
                start_node = next((n for n in workflow['nodes'] if 'start' in n['type'].lower()), None)
                if start_node:
                    input_text = start_node.get('data', {}).get('initial_input', 'Hello')
                else:
                    input_text = 'Test input'
            
            print(f"ğŸ“ Input: {input_text}")
            
            # Workflow'Ä± validate et
            validation_result = self.engine.validate(workflow)
            if not validation_result.get("valid", True):
                errors = validation_result.get("errors", ["Validation failed"])
                raise ValueError(f"Workflow validation failed: {', '.join(errors)}")
            
            print("âœ… Workflow validation passed")
            
            # Workflow'Ä± build et
            self.engine.build(flow_data=workflow)
            print("âœ… Workflow graph built")
            
            # Execute et
            result_stream = await self.engine.execute(inputs={"input": input_text})
            
            # Stream'den sonucu al
            if hasattr(result_stream, '__aiter__'):
                # Async generator ise son sonucu al
                final_result = None
                async for chunk in result_stream:
                    if isinstance(chunk, dict) and 'result' in chunk:
                        final_result = chunk['result']
                    elif isinstance(chunk, dict) and 'output' in chunk:
                        final_result = chunk['output']
                result = final_result or result_stream
            else:
                result = result_stream
            
            execution_time = time.time() - start_time
            
            print(f"âœ… Execution completed in {execution_time:.2f}s")
            print(f"ğŸ“Š Result: {result}")
            
            # Test sonucunu kaydet
            test_result = {
                "workflow": workflow,
                "input": input_text,
                "result": result,
                "execution_time": execution_time,
                "timestamp": datetime.now().isoformat(),
                "success": True
            }
            
            return test_result
            
        except Exception as e:
            execution_time = time.time() - start_time
            print(f"âŒ Execution failed in {execution_time:.2f}s")
            print(f"ğŸ’¥ Error: {str(e)}")
            
            test_result = {
                "workflow": workflow,
                "input": input_text,
                "error": str(e),
                "execution_time": execution_time,
                "timestamp": datetime.now().isoformat(),
                "success": False
            }
            
            return test_result

    def save_test_result(self, test_result: Dict[str, Any], filename: str = None):
        """Test sonucunu kaydet."""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            workflow_name = test_result.get('workflow', {}).get('name', 'unnamed')
            filename = f"{workflow_name}_{timestamp}.json"
        
        result_file = self.test_results_dir / filename
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(test_result, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"ğŸ’¾ Test result saved: {result_file}")

    def interactive_mode(self):
        """Interactive mode ile workflow build et."""
        print("\nğŸ”§ Interactive Workflow Builder")
        print("=" * 40)
        
        workflow = {
            "name": input("Workflow name: "),
            "description": input("Description: "),
            "nodes": [],
            "edges": []
        }
        
        # Node'larÄ± ekle
        print("\nğŸ§© Adding nodes (type 'done' to finish):")
        node_counter = 1
        
        while True:
            node_type = input(f"\nNode {node_counter} type (or 'done'): ")
            if node_type.lower() == 'done':
                break
            
            if node_type not in self.available_nodes:
                print(f"âŒ Unknown node type. Available: {list(self.available_nodes.keys())[:5]}...")
                continue
            
            node_id = f"{node_type.lower()}_{node_counter}"
            node = {
                "id": node_id,
                "type": node_type,
                "position": {"x": node_counter * 200, "y": 100},
                "data": {}
            }
            
            # Node data'sÄ±nÄ± topla
            print(f"Configure {node_type} (press Enter to skip):")
            # Bu kÄ±sÄ±m node tÃ¼rÃ¼ne gÃ¶re dinamik olabilir
            
            workflow["nodes"].append(node)
            node_counter += 1
        
        # Edge'leri ekle
        print("\nğŸ”— Adding connections:")
        for i in range(len(workflow["nodes"]) - 1):
            source = workflow["nodes"][i]["id"]
            target = workflow["nodes"][i + 1]["id"]
            
            workflow["edges"].append({
                "id": f"e{i + 1}",
                "source": source,
                "target": target
            })
        
        print(f"\nâœ… Workflow created with {len(workflow['nodes'])} nodes")
        return workflow


async def main():
    """Ana fonksiyon."""
    parser = argparse.ArgumentParser(description="KAI-Fusion Workflow Test Runner")
    parser.add_argument("--workflow", "-w", help="Workflow JSON file to execute")
    parser.add_argument("--input", "-i", help="Input text for workflow")
    parser.add_argument("--create", "-c", action="store_true", help="Create new workflow from template")
    parser.add_argument("--template", "-t", help="Template name for creation")
    parser.add_argument("--list-nodes", "-l", action="store_true", help="List available nodes")
    parser.add_argument("--interactive", action="store_true", help="Interactive workflow builder")
    parser.add_argument("--save-result", "-s", help="Save test result with filename")
    
    args = parser.parse_args()
    
    # Test runner'Ä± baÅŸlat
    runner = WorkflowTestRunner()
    
    if args.list_nodes:
        runner.list_available_nodes()
        return
    
    if args.interactive:
        workflow = runner.interactive_mode()
        if input("\nExecute workflow now? (y/N): ").lower() == 'y':
            result = await runner.execute_workflow(workflow, args.input)
            if args.save_result:
                runner.save_test_result(result, args.save_result)
        
        if input("Save as template? (y/N): ").lower() == 'y':
            template_name = input("Template name: ")
            runner.save_template(template_name, workflow)
        return
    
    if args.create and args.template:
        workflow = runner.create_workflow_template(args.template)
        runner.save_template(args.template, workflow)
        print(f"âœ… Template '{args.template}' created and saved")
        return
    
    if args.workflow:
        workflow = runner.load_workflow(args.workflow)
        result = await runner.execute_workflow(workflow, args.input)
        
        if args.save_result:
            runner.save_test_result(result, args.save_result)
        else:
            runner.save_test_result(result)
        
        return
    
    # HiÃ§ argÃ¼man verilmemiÅŸse help gÃ¶ster
    parser.print_help()


if __name__ == "__main__":
    asyncio.run(main())