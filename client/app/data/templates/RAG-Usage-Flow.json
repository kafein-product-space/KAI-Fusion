{
  "id": "rag-usage-flow",
  "name": "RAG Usage Flow",
  "description": "Complete RAG architecture with OpenAI LLM, embeddings, vector retrieval, and intelligent agent for document-based Q&A.",
  "colorFrom": "from-indigo-500",
  "colorTo": "to-purple-600",
  "icon": {
    "name": "search",
    "path": "icons/search.svg",
    "alt": "Search Icon"
  },
  "flow_data": {
    "edges": [
      {
        "id": "xy-edge__BufferMemory__7ef01e42-7d95-449c-8dd8-e2aa8c18e273memory-Agent__6742909d-34ab-4894-a73a-876a6edb77ffmemory",
        "type": "custom",
        "source": "BufferMemory__7ef01e42-7d95-449c-8dd8-e2aa8c18e273",
        "target": "Agent__6742909d-34ab-4894-a73a-876a6edb77ff",
        "sourceHandle": "memory",
        "targetHandle": "memory"
      },
      {
        "id": "xy-edge__OpenAIChat__fd701de5-2705-48b0-864f-a6faf615f781llm-Agent__6742909d-34ab-4894-a73a-876a6edb77ffllm",
        "type": "custom",
        "source": "OpenAIChat__fd701de5-2705-48b0-864f-a6faf615f781",
        "target": "Agent__6742909d-34ab-4894-a73a-876a6edb77ff",
        "sourceHandle": "llm",
        "targetHandle": "llm"
      },
      {
        "id": "xy-edge__StartNode__f0051d02-8f62-4a7e-9dea-fb9628f076c1output-Agent__6742909d-34ab-4894-a73a-876a6edb77ffinput",
        "type": "custom",
        "source": "StartNode__f0051d02-8f62-4a7e-9dea-fb9628f076c1",
        "target": "Agent__6742909d-34ab-4894-a73a-876a6edb77ff",
        "sourceHandle": "output",
        "targetHandle": "input"
      },
      {
        "id": "xy-edge__Agent__6742909d-34ab-4894-a73a-876a6edb77ffoutput-EndNode__7c28fe1b-17a8-406e-b406-58ab3a70976ftarget",
        "type": "custom",
        "source": "Agent__6742909d-34ab-4894-a73a-876a6edb77ff",
        "target": "EndNode__7c28fe1b-17a8-406e-b406-58ab3a70976f",
        "sourceHandle": "output",
        "targetHandle": "target"
      },
      {
        "id": "xy-edge__RetrieverProvider__aac9c0e1-0e3f-4e0f-ad6e-93204dd58f0eretriever_tool-Agent__6742909d-34ab-4894-a73a-876a6edb77fftools",
        "type": "custom",
        "source": "RetrieverProvider__aac9c0e1-0e3f-4e0f-ad6e-93204dd58f0e",
        "target": "Agent__6742909d-34ab-4894-a73a-876a6edb77ff",
        "sourceHandle": "retriever_tool",
        "targetHandle": "tools"
      },
      {
        "id": "xy-edge__OpenAIEmbeddingsProvider__19bda225-f933-4247-88da-57ac520bb963embedder-RetrieverProvider__aac9c0e1-0e3f-4e0f-ad6e-93204dd58f0eembedder",
        "type": "custom",
        "source": "OpenAIEmbeddingsProvider__19bda225-f933-4247-88da-57ac520bb963",
        "target": "RetrieverProvider__aac9c0e1-0e3f-4e0f-ad6e-93204dd58f0e",
        "sourceHandle": "embedder",
        "targetHandle": "embedder"
      },
      {
        "id": "xy-edge__CohereRerankerProvider__3e0b20d3-9bc7-41fc-80e7-26ba51d2c13dreranker-RetrieverProvider__aac9c0e1-0e3f-4e0f-ad6e-93204dd58f0ereranker",
        "type": "custom",
        "source": "CohereRerankerProvider__3e0b20d3-9bc7-41fc-80e7-26ba51d2c13d",
        "target": "RetrieverProvider__aac9c0e1-0e3f-4e0f-ad6e-93204dd58f0e",
        "sourceHandle": "reranker",
        "targetHandle": "reranker"
      }
    ],
    "nodes": [
      {
        "id": "StartNode__f0051d02-8f62-4a7e-9dea-fb9628f076c1",
        "data": {
          "icon": {
            "alt": null,
            "name": "rocket",
            "path": null
          },
          "name": "start",
          "inputs": [
            {
              "name": "initial_input",
              "type": "string",
              "default": "",
              "required": false,
              "description": "Initial input text to start the workflow",
              "displayName": "Initial Input",
              "is_connection": false
            },
            {
              "name": "trigger_data",
              "type": "any",
              "required": false,
              "description": "Data received from trigger nodes",
              "displayName": "Trigger Data",
              "is_connection": true
            }
          ],
          "outputs": [
            {
              "name": "output",
              "type": "string",
              "description": "Forwarded input to start the workflow chain",
              "displayName": "Execute",
              "is_connection": true
            }
          ],
          "metadata": {
            "id": "StartNode",
            "icon": {
              "alt": null,
              "name": "rocket",
              "path": null
            },
            "name": "StartNode",
            "tags": [],
            "colors": [
              "green-500",
              "emerald-600"
            ],
            "inputs": [
              {
                "name": "initial_input",
                "type": "string",
                "default": "",
                "required": false,
                "description": "Initial input text to start the workflow",
                "displayName": "Initial Input",
                "is_connection": false
              },
              {
                "name": "trigger_data",
                "type": "any",
                "required": false,
                "description": "Data received from trigger nodes",
                "displayName": "Trigger Data",
                "is_connection": true
              }
            ],
            "outputs": [
              {
                "name": "output",
                "type": "string",
                "description": "Forwarded input to start the workflow chain",
                "displayName": "Execute",
                "is_connection": true
              }
            ],
            "version": "1.0.0",
            "category": "Special",
            "examples": [],
            "node_type": "terminator",
            "properties": [],
            "description": "Entry point for workflow execution. Receives initial input and starts the workflow.",
            "display_name": "Start"
          },
          "description": "Entry point for workflow execution. Receives initial input and starts the workflow.",
          "displayName": "Start"
        },
        "type": "StartNode",
        "dragging": false,
        "measured": {
          "width": 96,
          "height": 96
        },
        "position": {
          "x": 860,
          "y": 380
        },
        "selected": false
      },
      {
        "id": "Agent__6742909d-34ab-4894-a73a-876a6edb77ff",
        "data": {
          "icon": {
            "alt": null,
            "name": "bot",
            "path": null
          },
          "name": "agent",
          "inputs": [
            {
              "name": "input",
              "type": "string",
              "required": true,
              "description": "The user's input to the agent.",
              "displayName": "Input",
              "is_connection": true
            },
            {
              "name": "llm",
              "type": "BaseLanguageModel",
              "required": true,
              "direction": "bottom",
              "description": "The language model that the agent will use.",
              "displayName": "LLM",
              "is_connection": true
            },
            {
              "name": "tools",
              "type": "Sequence[BaseTool]",
              "required": false,
              "direction": "bottom",
              "description": "The tools that the agent can use.",
              "displayName": "Tools",
              "is_connection": true
            },
            {
              "name": "memory",
              "type": "BaseMemory",
              "required": false,
              "direction": "bottom",
              "description": "The memory that the agent can use.",
              "displayName": "Memory",
              "is_connection": true
            },
            {
              "name": "max_iterations",
              "type": "int",
              "default": 10,
              "required": true,
              "description": "The maximum number of iterations the agent can perform.",
              "is_connection": false
            },
            {
              "name": "system_prompt",
              "type": "str",
              "default": "You are a helpful assistant.",
              "required": true,
              "description": "The system prompt for the agent.",
              "is_connection": false
            }
          ],
          "outputs": [
            {
              "name": "output",
              "type": "str",
              "description": "The final output from the agent.",
              "displayName": "Output",
              "is_connection": true
            }
          ],
          "metadata": {
            "id": "Agent",
            "icon": {
              "alt": null,
              "name": "bot",
              "path": null
            },
            "name": "Agent",
            "tags": [],
            "colors": [
              "purple-500",
              "indigo-600"
            ],
            "inputs": [
              {
                "name": "input",
                "type": "string",
                "required": true,
                "description": "The user's input to the agent.",
                "displayName": "Input",
                "is_connection": true
              },
              {
                "name": "llm",
                "type": "BaseLanguageModel",
                "required": true,
                "direction": "bottom",
                "description": "The language model that the agent will use.",
                "displayName": "LLM",
                "is_connection": true
              },
              {
                "name": "tools",
                "type": "Sequence[BaseTool]",
                "required": false,
                "direction": "bottom",
                "description": "The tools that the agent can use.",
                "displayName": "Tools",
                "is_connection": true
              },
              {
                "name": "memory",
                "type": "BaseMemory",
                "required": false,
                "direction": "bottom",
                "description": "The memory that the agent can use.",
                "displayName": "Memory",
                "is_connection": true
              },
              {
                "name": "max_iterations",
                "type": "int",
                "default": 10,
                "required": true,
                "description": "The maximum number of iterations the agent can perform.",
                "is_connection": false
              },
              {
                "name": "system_prompt",
                "type": "str",
                "default": "You are a helpful assistant.",
                "required": true,
                "description": "The system prompt for the agent.",
                "is_connection": false
              }
            ],
            "outputs": [
              {
                "name": "output",
                "type": "str",
                "description": "The final output from the agent.",
                "displayName": "Output",
                "is_connection": true
              }
            ],
            "version": "1.0.0",
            "category": "Agents",
            "examples": [],
            "node_type": "processor",
            "properties": [
              {
                "name": "agent_type",
                "rows": 4,
                "type": "select",
                "default": "react",
                "options": [
                  {
                    "label": "ReAct Agent ‚≠ê",
                    "value": "react"
                  },
                  {
                    "label": "Conversational Agent",
                    "value": "conversational"
                  },
                  {
                    "label": "Task-Oriented Agent",
                    "value": "task_oriented"
                  }
                ],
                "required": true,
                "displayName": "Agent Type"
              },
              {
                "hint": "Define agent behavior and capabilities. This is the core system instruction.",
                "name": "system_prompt",
                "rows": 4,
                "type": "textarea",
                "default": "You are a helpful assistant. Use tools to answer questions.",
                "required": true,
                "displayName": "System Prompt"
              },
              {
                "hint": "Template for user input using ${{variable}} syntax",
                "name": "user_prompt_template",
                "rows": 4,
                "type": "textarea",
                "default": "${{input}}",
                "required": false,
                "displayName": "User Prompt Template"
              },
              {
                "max": 20,
                "min": 1,
                "name": "max_iterations",
                "rows": 4,
                "type": "range",
                "default": 5,
                "maxLabel": "Thorough",
                "minLabel": "Quick",
                "required": true,
                "displayName": "Max Iterations"
              },
              {
                "max": 2,
                "min": 0,
                "name": "temperature",
                "rows": 4,
                "step": 0.1,
                "type": "range",
                "color": "purple-400",
                "default": 0.7,
                "maxLabel": "Creative",
                "minLabel": "Precise",
                "required": true,
                "displayName": "Temperature"
              },
              {
                "hint": "Allow agent to remember previous interactions",
                "name": "enable_memory",
                "rows": 4,
                "type": "checkbox",
                "default": true,
                "required": true,
                "displayName": "Enable Memory"
              },
              {
                "hint": "Allow agent to use connected tools and functions",
                "name": "enable_tools",
                "rows": 4,
                "type": "checkbox",
                "default": true,
                "required": true,
                "displayName": "Enable Tools"
              }
            ],
            "description": "Orchestrates LLM, tools, and memory for complex, multi-step tasks.",
            "display_name": "Agent"
          },
          "description": "Orchestrates LLM, tools, and memory for complex, multi-step tasks.",
          "displayName": "Agent"
        },
        "type": "Agent",
        "dragging": false,
        "measured": {
          "width": 96,
          "height": 96
        },
        "position": {
          "x": 1170,
          "y": 380
        },
        "selected": false
      },
      {
        "id": "EndNode__7c28fe1b-17a8-406e-b406-58ab3a70976f",
        "data": {
          "icon": {
            "alt": null,
            "name": "flag",
            "path": null
          },
          "name": "end",
          "inputs": [
            {
              "name": "target",
              "type": "any",
              "required": true,
              "description": "The final data from the preceding node",
              "displayName": "Target",
              "is_connection": true
            }
          ],
          "outputs": [],
          "metadata": {
            "id": "EndNode",
            "icon": {
              "alt": null,
              "name": "flag",
              "path": null
            },
            "name": "EndNode",
            "tags": [],
            "colors": [
              "gray-500",
              "slate-600"
            ],
            "inputs": [
              {
                "name": "target",
                "type": "any",
                "required": true,
                "description": "The final data from the preceding node",
                "displayName": "Target",
                "is_connection": true
              }
            ],
            "outputs": [],
            "version": "1.0.0",
            "category": "Special",
            "examples": [],
            "node_type": "terminator",
            "properties": [],
            "description": "Marks the end of a workflow path",
            "display_name": "End"
          },
          "description": "Marks the end of a workflow path",
          "displayName": "End"
        },
        "type": "EndNode",
        "dragging": false,
        "measured": {
          "width": 96,
          "height": 96
        },
        "position": {
          "x": 1480,
          "y": 380
        },
        "selected": false
      },
      {
        "id": "OpenAIChat__fd701de5-2705-48b0-864f-a6faf615f781",
        "data": {
          "icon": {
            "alt": "openaiicons",
            "name": "openai",
            "path": "icons/openai.svg"
          },
          "name": "openai_gpt",
          "inputs": [
            {
              "name": "model_name",
              "type": "str",
              "default": "gpt-4o",
              "required": false,
              "description": "OpenAI model to use",
              "is_connection": false
            },
            {
              "name": "temperature",
              "type": "float",
              "default": 0.1,
              "required": false,
              "description": "Sampling temperature (0.0-2.0) - Controls randomness",
              "is_connection": false
            },
            {
              "name": "max_tokens",
              "type": "int",
              "default": 10000,
              "required": false,
              "description": "Maximum tokens to generate (default: model limit)",
              "is_connection": false
            },
            {
              "name": "top_p",
              "type": "float",
              "default": 1,
              "required": false,
              "description": "Nucleus sampling parameter (0.0-1.0)",
              "is_connection": false
            },
            {
              "name": "frequency_penalty",
              "type": "float",
              "default": 0,
              "required": false,
              "description": "Frequency penalty (-2.0 to 2.0)",
              "is_connection": false
            },
            {
              "name": "presence_penalty",
              "type": "float",
              "default": 0,
              "required": false,
              "description": "Presence penalty (-2.0 to 2.0)",
              "is_connection": false
            },
            {
              "name": "system_prompt",
              "type": "str",
              "default": "You are a helpful, accurate, and intelligent AI assistant.",
              "required": false,
              "description": "System prompt for the model",
              "is_connection": false
            },
            {
              "name": "streaming",
              "type": "bool",
              "default": false,
              "required": false,
              "description": "Enable streaming responses",
              "is_connection": false
            },
            {
              "name": "timeout",
              "type": "int",
              "default": 60,
              "required": false,
              "description": "Request timeout in seconds",
              "is_connection": false
            }
          ],
          "outputs": [
            {
              "name": "llm",
              "type": "llm",
              "direction": "top",
              "description": "OpenAI Chat LLM instance configured with specified parameters",
              "displayName": "LLM",
              "is_connection": true
            },
            {
              "name": "model_info",
              "type": "dict",
              "description": "Model configuration information",
              "is_connection": false
            },
            {
              "name": "usage_stats",
              "type": "dict",
              "description": "Token usage and cost information",
              "is_connection": false
            }
          ],
          "metadata": {
            "id": "OpenAIChat",
            "icon": {
              "alt": "openaiicons",
              "name": "openai",
              "path": "icons/openai.svg"
            },
            "name": "OpenAIChat",
            "tags": [],
            "colors": [
              "purple-500",
              "indigo-600"
            ],
            "inputs": [
              {
                "name": "model_name",
                "type": "str",
                "default": "gpt-4o",
                "required": false,
                "description": "OpenAI model to use",
                "is_connection": false
              },
              {
                "name": "temperature",
                "type": "float",
                "default": 0.1,
                "required": false,
                "description": "Sampling temperature (0.0-2.0) - Controls randomness",
                "is_connection": false
              },
              {
                "name": "max_tokens",
                "type": "int",
                "default": 10000,
                "required": false,
                "description": "Maximum tokens to generate (default: model limit)",
                "is_connection": false
              },
              {
                "name": "top_p",
                "type": "float",
                "default": 1,
                "required": false,
                "description": "Nucleus sampling parameter (0.0-1.0)",
                "is_connection": false
              },
              {
                "name": "frequency_penalty",
                "type": "float",
                "default": 0,
                "required": false,
                "description": "Frequency penalty (-2.0 to 2.0)",
                "is_connection": false
              },
              {
                "name": "presence_penalty",
                "type": "float",
                "default": 0,
                "required": false,
                "description": "Presence penalty (-2.0 to 2.0)",
                "is_connection": false
              },
              {
                "name": "system_prompt",
                "type": "str",
                "default": "You are a helpful, accurate, and intelligent AI assistant.",
                "required": false,
                "description": "System prompt for the model",
                "is_connection": false
              },
              {
                "name": "streaming",
                "type": "bool",
                "default": false,
                "required": false,
                "description": "Enable streaming responses",
                "is_connection": false
              },
              {
                "name": "timeout",
                "type": "int",
                "default": 60,
                "required": false,
                "description": "Request timeout in seconds",
                "is_connection": false
              }
            ],
            "outputs": [
              {
                "name": "llm",
                "type": "llm",
                "direction": "top",
                "description": "OpenAI Chat LLM instance configured with specified parameters",
                "displayName": "LLM",
                "is_connection": true
              },
              {
                "name": "model_info",
                "type": "dict",
                "description": "Model configuration information",
                "is_connection": false
              },
              {
                "name": "usage_stats",
                "type": "dict",
                "description": "Token usage and cost information",
                "is_connection": false
              }
            ],
            "version": "1.0.0",
            "category": "LLM",
            "examples": [],
            "node_type": "provider",
            "properties": [
              {
                "name": "credential_id",
                "rows": 4,
                "type": "credential-select",
                "required": false,
                "displayName": "Credential",
                "placeholder": "Select Credential",
                "serviceType": "openai"
              },
              {
                "name": "model_name",
                "rows": 4,
                "type": "select",
                "default": "gpt-4o",
                "options": [
                  {
                    "label": "GPT-4o",
                    "value": "gpt-4o"
                  },
                  {
                    "label": "GPT-4o Mini",
                    "value": "gpt-4o-mini"
                  },
                  {
                    "label": "GPT-4 Turbo",
                    "value": "gpt-4-turbo"
                  },
                  {
                    "label": "GPT-4",
                    "value": "gpt-4"
                  },
                  {
                    "label": "GPT-4 32K",
                    "value": "gpt-4-32k"
                  }
                ],
                "required": true,
                "displayName": "Model"
              },
              {
                "max": 2,
                "min": 0,
                "name": "temperature",
                "rows": 4,
                "step": 0.1,
                "type": "range",
                "default": 0.7,
                "maxLabel": "Creative",
                "minLabel": "Precise",
                "required": true,
                "displayName": "Temperature"
              },
              {
                "max": 4096,
                "min": 1,
                "name": "max_tokens",
                "rows": 4,
                "type": "number",
                "default": 1000,
                "required": true,
                "displayName": "Max Tokens"
              }
            ],
            "description": "OpenAI Chat completion using latest GPT models with advanced configuration",
            "display_name": "OpenAI GPT"
          },
          "description": "OpenAI Chat completion using latest GPT models with advanced configuration",
          "displayName": "OpenAI GPT"
        },
        "type": "OpenAIChat",
        "dragging": false,
        "measured": {
          "width": 96,
          "height": 96
        },
        "position": {
          "x": 1020,
          "y": 530
        },
        "selected": false
      },
      {
        "id": "BufferMemory__7ef01e42-7d95-449c-8dd8-e2aa8c18e273",
        "data": {
          "icon": {
            "alt": null,
            "name": "database",
            "path": null
          },
          "name": "buffer_memory_persistent",
          "inputs": [
            {
              "name": "return_messages",
              "type": "bool",
              "default": true,
              "required": true,
              "description": "Return as messages.",
              "is_connection": false
            },
            {
              "name": "input_key",
              "type": "str",
              "default": "input",
              "required": true,
              "description": "Key for user input.",
              "is_connection": false
            },
            {
              "name": "user_id",
              "type": "str",
              "required": false,
              "description": "User ID for multi-tenancy.",
              "is_connection": false
            }
          ],
          "outputs": [
            {
              "name": "memory",
              "type": "BaseChatMemory",
              "direction": "top",
              "description": "Configured buffer memory instance.",
              "displayName": "Memory",
              "is_connection": true
            }
          ],
          "metadata": {
            "id": "BufferMemory",
            "icon": {
              "alt": null,
              "name": "database",
              "path": null
            },
            "name": "BufferMemory",
            "tags": [],
            "colors": [
              "blue-500",
              "indigo-600"
            ],
            "inputs": [
              {
                "name": "return_messages",
                "type": "bool",
                "default": true,
                "required": true,
                "description": "Return as messages.",
                "is_connection": false
              },
              {
                "name": "input_key",
                "type": "str",
                "default": "input",
                "required": true,
                "description": "Key for user input.",
                "is_connection": false
              },
              {
                "name": "user_id",
                "type": "str",
                "required": false,
                "description": "User ID for multi-tenancy.",
                "is_connection": false
              }
            ],
            "outputs": [
              {
                "name": "memory",
                "type": "BaseChatMemory",
                "direction": "top",
                "description": "Configured buffer memory instance.",
                "displayName": "Memory",
                "is_connection": true
              }
            ],
            "version": "1.0.0",
            "category": "Other",
            "examples": [],
            "node_type": "memory",
            "properties": [
              {
                "name": "memory_key",
                "rows": 4,
                "type": "text",
                "default": "memory",
                "required": true,
                "displayName": "MEMORY KEY"
              },
              {
                "name": "input_key",
                "rows": 4,
                "type": "text",
                "default": "input",
                "required": true,
                "displayName": "INPUT KEY"
              },
              {
                "name": "output_key",
                "rows": 4,
                "type": "text",
                "default": "output",
                "required": true,
                "displayName": "OUTPUT KEY"
              },
              {
                "name": "return_messages",
                "rows": 4,
                "type": "checkbox",
                "default": true,
                "required": false,
                "displayName": "Return Messages"
              }
            ],
            "description": "Stores entire conversation history with database persistence.",
            "display_name": "Buffer Memory (Persistent)"
          },
          "description": "Stores entire conversation history with database persistence.",
          "displayName": "Buffer Memory (Persistent)"
        },
        "type": "BufferMemory",
        "dragging": false,
        "measured": {
          "width": 96,
          "height": 96
        },
        "position": {
          "x": 1320,
          "y": 530
        },
        "selected": false
      },
      {
        "id": "RetrieverProvider__aac9c0e1-0e3f-4e0f-ad6e-93204dd58f0e",
        "data": {
          "icon": {
            "alt": null,
            "name": "file-stack",
            "path": null
          },
          "name": "retriever_provider",
          "inputs": [
            {
              "name": "collection_name",
              "type": "str",
              "required": true,
              "description": "Vector collection name in the database",
              "is_connection": false
            },
            {
              "name": "search_k",
              "type": "int",
              "default": 6,
              "required": false,
              "description": "Number of documents to retrieve",
              "is_connection": false
            },
            {
              "name": "search_type",
              "type": "str",
              "default": "similarity",
              "required": false,
              "description": "Search type for retrieval",
              "is_connection": false
            },
            {
              "name": "score_threshold",
              "type": "float",
              "default": 0,
              "required": false,
              "description": "Minimum similarity score threshold (0.0-1.0)",
              "is_connection": false
            },
            {
              "name": "metadata_filter",
              "type": "json",
              "default": "{}",
              "required": false,
              "description": "Filter documents by metadata (JSON format)",
              "is_connection": false
            },
            {
              "name": "filter_strategy",
              "type": "select",
              "default": "exact",
              "required": false,
              "description": "How to apply metadata filters",
              "is_connection": false
            },
            {
              "name": "enable_metadata_filtering",
              "type": "boolean",
              "default": false,
              "required": false,
              "description": "Enable metadata-based filtering for search results",
              "is_connection": false
            },
            {
              "name": "embedder",
              "type": "embedder",
              "required": true,
              "direction": "bottom",
              "description": "Embedder service for retrieval (OpenAIEmbeddings, etc.)",
              "displayName": "Embedder",
              "is_connection": true
            },
            {
              "name": "reranker",
              "type": "reranker",
              "required": false,
              "direction": "bottom",
              "description": "Optional reranker service for enhanced retrieval (CohereReranker, etc.)",
              "displayName": "Reranker",
              "is_connection": true
            }
          ],
          "outputs": [
            {
              "name": "retriever_tool",
              "type": "BaseTool",
              "direction": "top",
              "description": "Configured retriever tool ready for use with agents",
              "displayName": "Retriever Tool",
              "is_connection": true
            }
          ],
          "metadata": {
            "id": "RetrieverProvider",
            "icon": {
              "alt": null,
              "name": "file-stack",
              "path": null
            },
            "name": "RetrieverProvider",
            "tags": [],
            "colors": [
              "indigo-500",
              "purple-600"
            ],
            "inputs": [
              {
                "name": "collection_name",
                "type": "str",
                "required": true,
                "description": "Vector collection name in the database",
                "is_connection": false
              },
              {
                "name": "search_k",
                "type": "int",
                "default": 6,
                "required": false,
                "description": "Number of documents to retrieve",
                "is_connection": false
              },
              {
                "name": "search_type",
                "type": "str",
                "default": "similarity",
                "required": false,
                "description": "Search type for retrieval",
                "is_connection": false
              },
              {
                "name": "score_threshold",
                "type": "float",
                "default": 0,
                "required": false,
                "description": "Minimum similarity score threshold (0.0-1.0)",
                "is_connection": false
              },
              {
                "name": "metadata_filter",
                "type": "json",
                "default": "{}",
                "required": false,
                "description": "Filter documents by metadata (JSON format)",
                "is_connection": false
              },
              {
                "name": "filter_strategy",
                "type": "select",
                "default": "exact",
                "required": false,
                "description": "How to apply metadata filters",
                "is_connection": false
              },
              {
                "name": "enable_metadata_filtering",
                "type": "boolean",
                "default": false,
                "required": false,
                "description": "Enable metadata-based filtering for search results",
                "is_connection": false
              },
              {
                "name": "embedder",
                "type": "embedder",
                "required": true,
                "direction": "bottom",
                "description": "Embedder service for retrieval (OpenAIEmbeddings, etc.)",
                "displayName": "Embedder",
                "is_connection": true
              },
              {
                "name": "reranker",
                "type": "reranker",
                "required": false,
                "direction": "bottom",
                "description": "Optional reranker service for enhanced retrieval (CohereReranker, etc.)",
                "displayName": "Reranker",
                "is_connection": true
              }
            ],
            "outputs": [
              {
                "name": "retriever_tool",
                "type": "BaseTool",
                "direction": "top",
                "description": "Configured retriever tool ready for use with agents",
                "displayName": "Retriever Tool",
                "is_connection": true
              }
            ],
            "version": "1.0.0",
            "category": "Tool",
            "examples": [],
            "node_type": "provider",
            "properties": [
              {
                "name": "credential_id",
                "rows": 4,
                "type": "credential-select",
                "required": false,
                "displayName": "Select Credential",
                "placeholder": "Select Credential"
              },
              {
                "name": "collection_name",
                "rows": 4,
                "type": "text",
                "required": true,
                "displayName": "Collection Name",
                "placeholder": "e.g., documents, products, knowledge_base"
              },
              {
                "hint": "Similarity search for exact matches, MMR for diverse results",
                "name": "search_type",
                "rows": 4,
                "type": "select",
                "default": "similarity",
                "options": [
                  {
                    "label": "Similarity Search",
                    "value": "similarity"
                  },
                  {
                    "label": "MMR (Maximal Marginal Relevance)",
                    "value": "mmr"
                  }
                ],
                "required": true,
                "displayName": "Search Type"
              },
              {
                "max": 50,
                "min": 1,
                "name": "search_k",
                "rows": 4,
                "type": "range",
                "default": 6,
                "maxLabel": "Many Results",
                "minLabel": "Few Results",
                "required": true,
                "displayName": "Search K"
              },
              {
                "max": 1,
                "min": 0,
                "name": "score_threshold",
                "rows": 4,
                "step": 0.05,
                "type": "range",
                "default": 0,
                "maxLabel": "Strict",
                "minLabel": "Inclusive",
                "required": true,
                "displayName": "Score Threshold"
              },
              {
                "hint": "Enable metadata-based filtering for search results",
                "name": "enable_metadata_filtering",
                "rows": 4,
                "type": "checkbox",
                "default": false,
                "required": true,
                "displayName": "Enable Metadata Filtering"
              },
              {
                "name": "metadata_filter",
                "rows": 4,
                "type": "json-editor",
                "required": true,
                "description": "Filter documents by metadata (JSON format)",
                "displayName": "Metadata Filter",
                "displayOptions": {
                  "show": {
                    "enable_metadata_filtering": true
                  }
                }
              },
              {
                "hint": "How to apply metadata filters",
                "name": "filter_strategy",
                "rows": 4,
                "type": "select",
                "default": "exact",
                "options": [
                  {
                    "label": "Exact Match",
                    "value": "exact"
                  },
                  {
                    "label": "Contains",
                    "value": "contains"
                  },
                  {
                    "label": "Any Match (OR)",
                    "value": "or"
                  }
                ],
                "required": true,
                "displayName": "Filter Strategy",
                "displayOptions": {
                  "show": {
                    "enable_metadata_filtering": true
                  }
                }
              }
            ],
            "description": "Provider node that creates configured retriever tools for agents. Connect to a vector database and embeddings provider to create a search tool for your agents.",
            "display_name": "Retriever Provider"
          },
          "description": "Provider node that creates configured retriever tools for agents. Connect to a vector database and embeddings provider to create a search tool for your agents.",
          "displayName": "Retriever Provider"
        },
        "type": "RetrieverProvider",
        "dragging": false,
        "measured": {
          "width": 96,
          "height": 96
        },
        "position": {
          "x": 1170,
          "y": 530
        },
        "selected": false
      },
      {
        "id": "OpenAIEmbeddingsProvider__19bda225-f933-4247-88da-57ac520bb963",
        "data": {
          "icon": {
            "alt": "openaiicons",
            "name": "openai",
            "path": "icons/openai.svg"
          },
          "name": "openai_embeddings_provider",
          "inputs": [
            {
              "name": "openai_api_key",
              "type": "str",
              "required": false,
              "description": "OpenAI API Key (leave empty to use OPENAI_API_KEY environment variable)",
              "is_connection": false
            },
            {
              "name": "model",
              "type": "str",
              "default": "text-embedding-3-small",
              "required": false,
              "description": "OpenAI embedding model to use",
              "is_connection": false
            },
            {
              "name": "request_timeout",
              "type": "int",
              "default": 60,
              "required": false,
              "description": "Request timeout in seconds",
              "is_connection": false
            },
            {
              "name": "max_retries",
              "type": "int",
              "default": 3,
              "required": false,
              "description": "Maximum number of retries for failed requests",
              "is_connection": false
            }
          ],
          "outputs": [
            {
              "name": "embedder",
              "type": "OpenAIEmbeddings",
              "direction": "top",
              "description": "Configured OpenAIEmbeddings instance ready for use",
              "displayName": "Embedder",
              "is_connection": true
            }
          ],
          "metadata": {
            "id": "OpenAIEmbeddingsProvider",
            "icon": {
              "alt": "openaiicons",
              "name": "openai",
              "path": "icons/openai.svg"
            },
            "name": "OpenAIEmbeddingsProvider",
            "tags": [],
            "colors": [
              "cyan-500",
              "blue-600"
            ],
            "inputs": [
              {
                "name": "openai_api_key",
                "type": "str",
                "required": false,
                "description": "OpenAI API Key (leave empty to use OPENAI_API_KEY environment variable)",
                "is_connection": false
              },
              {
                "name": "model",
                "type": "str",
                "default": "text-embedding-3-small",
                "required": false,
                "description": "OpenAI embedding model to use",
                "is_connection": false
              },
              {
                "name": "request_timeout",
                "type": "int",
                "default": 60,
                "required": false,
                "description": "Request timeout in seconds",
                "is_connection": false
              },
              {
                "name": "max_retries",
                "type": "int",
                "default": 3,
                "required": false,
                "description": "Maximum number of retries for failed requests",
                "is_connection": false
              }
            ],
            "outputs": [
              {
                "name": "embedder",
                "type": "OpenAIEmbeddings",
                "direction": "top",
                "description": "Configured OpenAIEmbeddings instance ready for use",
                "displayName": "Embedder",
                "is_connection": true
              }
            ],
            "version": "1.0.0",
            "category": "Embedding",
            "examples": [],
            "node_type": "provider",
            "properties": [
              {
                "hint": "The model to use for generating embeddings.",
                "name": "model",
                "rows": 4,
                "type": "select",
                "default": "text-embedding-3-small",
                "options": [
                  {
                    "label": "text-embedding-3-small (1536D)",
                    "value": "text-embedding-3-small"
                  },
                  {
                    "label": "text-embedding-3-large (3072D)",
                    "value": "text-embedding-3-large"
                  },
                  {
                    "label": "text-embedding-ada-002 (1536D)",
                    "value": "text-embedding-ada-002"
                  }
                ],
                "required": true,
                "displayName": "Embedding Model"
              },
              {
                "name": "credential_id",
                "rows": 4,
                "type": "credential-select",
                "required": false,
                "displayName": "Select Credential",
                "placeholder": "Select Credential",
                "serviceType": "openai"
              },
              {
                "hint": "OpenAI Organization ID.",
                "name": "organization",
                "rows": 4,
                "type": "text",
                "required": false,
                "displayName": "Organization (Optional)",
                "placeholder": "org-..."
              },
              {
                "max": 100,
                "min": 1,
                "hint": "Number of texts to embed in a single batch.",
                "name": "batch_size",
                "rows": 4,
                "type": "number",
                "default": 100,
                "required": true,
                "displayName": "Batch Size"
              },
              {
                "max": 10,
                "min": 0,
                "hint": "Maximum number of retries for failed requests.",
                "name": "max_retries",
                "rows": 4,
                "type": "number",
                "default": 3,
                "required": true,
                "displayName": "Max Retries"
              },
              {
                "max": 300,
                "min": 10,
                "hint": "Timeout for API requests in seconds.",
                "name": "request_timeout",
                "rows": 4,
                "type": "number",
                "default": 30,
                "required": true,
                "displayName": "Request Timeout (seconds)"
              },
              {
                "hint": "Auto-calculated based on model selection.",
                "name": "dimensions",
                "rows": 4,
                "type": "number",
                "default": 1536,
                "required": true,
                "displayName": "Dimensions"
              }
            ],
            "description": "Provider node that creates configured OpenAIEmbeddings instances. Use this node to create a shared embeddings instance for your workflow.",
            "display_name": "OpenAI Embeddings Provider"
          },
          "description": "Provider node that creates configured OpenAIEmbeddings instances. Use this node to create a shared embeddings instance for your workflow.",
          "displayName": "OpenAI Embeddings Provider"
        },
        "type": "OpenAIEmbeddingsProvider",
        "dragging": false,
        "measured": {
          "width": 96,
          "height": 96
        },
        "position": {
          "x": 1100,
          "y": 700
        },
        "selected": false
      },
      {
        "id": "CohereRerankerProvider__3e0b20d3-9bc7-41fc-80e7-26ba51d2c13d",
        "data": {
          "icon": {
            "alt": "coherererankericons",
            "name": "cohere",
            "path": "icons/cohere.svg"
          },
          "name": "cohere_reranker_provider",
          "inputs": [
            {
              "name": "model",
              "type": "str",
              "default": "rerank-english-v3.0",
              "required": false,
              "description": "Cohere reranking model to use",
              "is_connection": false
            },
            {
              "name": "top_n",
              "type": "int",
              "required": true,
              "description": "Number of top results to return",
              "is_connection": false
            }
          ],
          "outputs": [
            {
              "name": "reranker",
              "type": "CohereRerank",
              "direction": "top",
              "description": "Configured Cohere reranker compressor ready for use",
              "displayName": "Reranker Model",
              "is_connection": true
            }
          ],
          "metadata": {
            "id": "CohereRerankerProvider",
            "icon": {
              "alt": "coherererankericons",
              "name": "cohere",
              "path": "icons/cohere.svg"
            },
            "name": "CohereRerankerProvider",
            "tags": [],
            "colors": [
              "orange-500",
              "red-600"
            ],
            "inputs": [
              {
                "name": "model",
                "type": "str",
                "default": "rerank-english-v3.0",
                "required": false,
                "description": "Cohere reranking model to use",
                "is_connection": false
              },
              {
                "name": "top_n",
                "type": "int",
                "required": true,
                "description": "Number of top results to return",
                "is_connection": false
              }
            ],
            "outputs": [
              {
                "name": "reranker",
                "type": "CohereRerank",
                "direction": "top",
                "description": "Configured Cohere reranker compressor ready for use",
                "displayName": "Reranker Model",
                "is_connection": true
              }
            ],
            "version": "1.0.0",
            "category": "Tool",
            "examples": [],
            "node_type": "provider",
            "properties": [
              {
                "name": "credential_id",
                "rows": 4,
                "type": "credential-select",
                "required": false,
                "displayName": "Select Credential",
                "placeholder": "Select Credential",
                "serviceType": "cohere"
              },
              {
                "name": "model",
                "rows": 4,
                "type": "select",
                "default": "rerank-english-v3.0",
                "options": [
                  {
                    "label": "Rerank English v3.0",
                    "value": "rerank-english-v3.0"
                  },
                  {
                    "label": "Rerank Multilingual v3.0",
                    "value": "rerank-multilingual-v3.0"
                  },
                  {
                    "label": "Rerank English v2.0",
                    "value": "rerank-english-v2.0"
                  },
                  {
                    "label": "Rerank Multilingual v2.0",
                    "value": "rerank-multilingual-v2.0"
                  }
                ],
                "required": true,
                "displayName": "Model"
              },
              {
                "max": 20,
                "min": 1,
                "name": "top_n",
                "rows": 4,
                "type": "range",
                "default": 10,
                "maxLabel": "20",
                "minLabel": "1",
                "required": true,
                "displayName": "Top N"
              },
              {
                "max": 50,
                "min": 1,
                "name": "max_chunks_per_doc",
                "rows": 4,
                "type": "range",
                "color": "green-500",
                "default": 10,
                "maxLabel": "50",
                "minLabel": "1",
                "required": true,
                "displayName": "Max Chunks Per Doc"
              }
            ],
            "description": "Provider node that creates configured Cohere reranker instances. Use this node to create a shared reranker for your workflow.",
            "display_name": "Cohere Reranker Provider"
          },
          "description": "Provider node that creates configured Cohere reranker instances. Use this node to create a shared reranker for your workflow.",
          "displayName": "Cohere Reranker Provider"
        },
        "type": "CohereRerankerProvider",
        "dragging": false,
        "measured": {
          "width": 96,
          "height": 96
        },
        "position": {
          "x": 1260,
          "y": 700
        },
        "selected": true
      }
    ]
  }
}